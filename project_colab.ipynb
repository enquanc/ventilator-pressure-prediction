{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxBA5_2b_iiV"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xttpe7v4_aI_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
        "\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_absolute_error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyZRr_hC_mmD"
      },
      "outputs": [],
      "source": [
        "data_train = pd.read_csv(\"/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/train.csv\")\n",
        "data_test = pd.read_csv(\"/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/test.csv\")\n",
        "data_submission = pd.read_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqN1T6yk_aJN",
        "outputId": "80036317-29c3-4e95-d001-04166415027f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step-1...Completed\n",
            "Step-2...Completed\n",
            "Step-3...Completed\n",
            "Step-4...Completed\n",
            "Step-5...Completed\n",
            "Step-6...Completed\n",
            "Step-7...Completed\n",
            "Step-8...Completed\n",
            "Step-1...Completed\n",
            "Step-2...Completed\n",
            "Step-3...Completed\n",
            "Step-4...Completed\n",
            "Step-5...Completed\n",
            "Step-6...Completed\n",
            "Step-7...Completed\n",
            "Step-8...Completed\n"
          ]
        }
      ],
      "source": [
        "def add_features(df):\n",
        "    df['cross']= df['u_in'] * df['u_out']\n",
        "    df['cross2']= df['time_step'] * df['u_out']\n",
        "    df['area'] = df['time_step'] * df['u_in']\n",
        "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
        "    df['time_step_cumsum'] = df.groupby(['breath_id'])['time_step'].cumsum()\n",
        "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
        "    print(\"Step-1...Completed\")\n",
        "    \n",
        "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
        "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
        "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
        "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
        "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
        "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
        "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
        "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
        "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
        "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
        "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
        "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
        "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
        "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
        "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
        "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
        "    df = df.fillna(0)\n",
        "    print(\"Step-2...Completed\")\n",
        "    \n",
        "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
        "    df['breath_id__u_in__mean'] = df.groupby(['breath_id'])['u_in'].transform('mean')\n",
        "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
        "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
        "\n",
        "    print(\"Step-3...Completed\")\n",
        "    \n",
        "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
        "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
        "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
        "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
        "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
        "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
        "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
        "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
        "    print(\"Step-4...Completed\")\n",
        "    \n",
        "    df['one'] = 1\n",
        "    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n",
        "    df['u_in_cummean'] =df['u_in_cumsum'] /df['count']\n",
        "    \n",
        "    df['breath_id_lag']=df['breath_id'].shift(1).fillna(0)\n",
        "    df['breath_id_lag2']=df['breath_id'].shift(2).fillna(0)\n",
        "    df['breath_id_lagsame']=np.select([df['breath_id_lag']==df['breath_id']],[1],0)\n",
        "    df['breath_id_lag2same']=np.select([df['breath_id_lag2']==df['breath_id']],[1],0)\n",
        "    df['breath_id__u_in_lag'] = df['u_in'].shift(1).fillna(0)\n",
        "    df['breath_id__u_in_lag'] = df['breath_id__u_in_lag'] * df['breath_id_lagsame']\n",
        "    df['breath_id__u_in_lag2'] = df['u_in'].shift(2).fillna(0)\n",
        "    df['breath_id__u_in_lag2'] = df['breath_id__u_in_lag2'] * df['breath_id_lag2same']\n",
        "    print(\"Step-5...Completed\")\n",
        "    \n",
        "    df['time_step_diff'] = df.groupby('breath_id')['time_step'].diff().fillna(0)\n",
        "    df['ewm_u_in_mean'] = (df\\\n",
        "                           .groupby('breath_id')['u_in']\\\n",
        "                           .ewm(halflife=9)\\\n",
        "                           .mean()\\\n",
        "                           .reset_index(level=0,drop=True))\n",
        "    df[[\"15_in_sum\",\"15_in_min\",\"15_in_max\",\"15_in_mean\"]] = (df\\\n",
        "                                                              .groupby('breath_id')['u_in']\\\n",
        "                                                              .rolling(window=15,min_periods=1)\\\n",
        "                                                              .agg({\"15_in_sum\":\"sum\",\n",
        "                                                                    \"15_in_min\":\"min\",\n",
        "                                                                    \"15_in_max\":\"max\",\n",
        "                                                                    \"15_in_mean\":\"mean\"\n",
        "                                                                    #\"15_in_std\":\"std\"\n",
        "                                                               })\\\n",
        "                                                               .reset_index(level=0,drop=True))\n",
        "    print(\"Step-6...Completed\")\n",
        "        \n",
        "    df['u_in_lagback_diff1'] = df['u_in'] - df['u_in_lag_back1']\n",
        "    df['u_out_lagback_diff1'] = df['u_out'] - df['u_out_lag_back1']\n",
        "    df['u_in_lagback_diff2'] = df['u_in'] - df['u_in_lag_back2']\n",
        "    df['u_out_lagback_diff2'] = df['u_out'] - df['u_out_lag_back2']\n",
        "    print(\"Step-7...Completed\")\n",
        "    \n",
        "    df['R'] = df['R'].astype(str)\n",
        "    df['C'] = df['C'].astype(str)\n",
        "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
        "    df = pd.get_dummies(df)\n",
        "    print(\"Step-8...Completed\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "train = add_features(data_train)\n",
        "test = add_features(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBQg_Q7P_aJS",
        "outputId": "fe224660-e12a-49d0-adc6-291633206133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape is now: (6036000, 73)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>breath_id</th>\n",
              "      <th>time_step</th>\n",
              "      <th>u_in</th>\n",
              "      <th>u_out</th>\n",
              "      <th>pressure</th>\n",
              "      <th>cross</th>\n",
              "      <th>cross2</th>\n",
              "      <th>area</th>\n",
              "      <th>time_step_cumsum</th>\n",
              "      <th>...</th>\n",
              "      <th>C_50</th>\n",
              "      <th>R__C_20__10</th>\n",
              "      <th>R__C_20__20</th>\n",
              "      <th>R__C_20__50</th>\n",
              "      <th>R__C_50__10</th>\n",
              "      <th>R__C_50__20</th>\n",
              "      <th>R__C_50__50</th>\n",
              "      <th>R__C_5__10</th>\n",
              "      <th>R__C_5__20</th>\n",
              "      <th>R__C_5__50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.083334</td>\n",
              "      <td>0</td>\n",
              "      <td>5.837492</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0.033652</td>\n",
              "      <td>18.383041</td>\n",
              "      <td>0</td>\n",
              "      <td>5.907794</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.618632</td>\n",
              "      <td>0.033652</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.067514</td>\n",
              "      <td>22.509278</td>\n",
              "      <td>0</td>\n",
              "      <td>7.876254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.138333</td>\n",
              "      <td>0.101167</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0.101542</td>\n",
              "      <td>22.808822</td>\n",
              "      <td>0</td>\n",
              "      <td>11.742872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.454391</td>\n",
              "      <td>0.202709</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0.135756</td>\n",
              "      <td>25.355850</td>\n",
              "      <td>0</td>\n",
              "      <td>12.234987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.896588</td>\n",
              "      <td>0.338464</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  breath_id  time_step       u_in  u_out   pressure  cross  cross2  \\\n",
              "0   1          1   0.000000   0.083334      0   5.837492    0.0     0.0   \n",
              "1   2          1   0.033652  18.383041      0   5.907794    0.0     0.0   \n",
              "2   3          1   0.067514  22.509278      0   7.876254    0.0     0.0   \n",
              "3   4          1   0.101542  22.808822      0  11.742872    0.0     0.0   \n",
              "4   5          1   0.135756  25.355850      0  12.234987    0.0     0.0   \n",
              "\n",
              "       area  time_step_cumsum  ...  C_50  R__C_20__10  R__C_20__20  \\\n",
              "0  0.000000          0.000000  ...     1            0            0   \n",
              "1  0.618632          0.033652  ...     1            0            0   \n",
              "2  2.138333          0.101167  ...     1            0            0   \n",
              "3  4.454391          0.202709  ...     1            0            0   \n",
              "4  7.896588          0.338464  ...     1            0            0   \n",
              "\n",
              "   R__C_20__50  R__C_50__10  R__C_50__20  R__C_50__50  R__C_5__10  R__C_5__20  \\\n",
              "0            1            0            0            0           0           0   \n",
              "1            1            0            0            0           0           0   \n",
              "2            1            0            0            0           0           0   \n",
              "3            1            0            0            0           0           0   \n",
              "4            1            0            0            0           0           0   \n",
              "\n",
              "   R__C_5__50  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Train shape is now:', train.shape )\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX6fXwn2_aJU"
      },
      "source": [
        "Auxiliary Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWDpecCn_aJX"
      },
      "outputs": [],
      "source": [
        "train['pressure_diff'] = train.groupby('breath_id').pressure.diff().fillna(0)\n",
        "train['pressure_integral'] = train.groupby('breath_id').pressure.cumsum()/200\n",
        "targets = train[['pressure','pressure_diff','pressure_integral']].to_numpy().reshape(-1, 80, 3)\n",
        "\n",
        "train.drop(['pressure','pressure_diff','pressure_integral','id', 'breath_id','one','count',\n",
        "            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n",
        "            'breath_id_lag2same'], axis=1, inplace=True)\n",
        "\n",
        "test.drop(['id', 'breath_id','one','count','breath_id_lag',\n",
        "            'breath_id_lag2','breath_id_lagsame',\n",
        "            'breath_id_lag2same'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmbhBWLg_aJZ",
        "outputId": "8cd70158-035f-45b8-e544-b2bce263652f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Targets shape is (75450, 80, 3)\n"
          ]
        }
      ],
      "source": [
        "print('Targets shape is',targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrguP-Xe_aJa"
      },
      "source": [
        "Rearrange Column Order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHJgDpwR_aJb",
        "outputId": "c23769b2-ac9c-4bc0-c20a-b0f64372e448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train columns:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['time_step', 'u_in', 'u_out', 'R_20', 'R_5', 'R_50', 'C_10',\n",
              "       'C_20', 'C_50', 'R__C_20__10', 'R__C_20__20', 'R__C_20__50',\n",
              "       'R__C_50__10', 'R__C_50__20', 'R__C_50__50', 'R__C_5__10',\n",
              "       'R__C_5__20', 'R__C_5__50', 'cross', 'cross2', 'area',\n",
              "       'time_step_cumsum', 'u_in_cumsum', 'u_in_lag1', 'u_out_lag1',\n",
              "       'u_in_lag_back1', 'u_out_lag_back1', 'u_in_lag2', 'u_out_lag2',\n",
              "       'u_in_lag_back2', 'u_out_lag_back2', 'u_in_lag3', 'u_out_lag3',\n",
              "       'u_in_lag_back3', 'u_out_lag_back3', 'u_in_lag4', 'u_out_lag4',\n",
              "       'u_in_lag_back4', 'u_out_lag_back4', 'breath_id__u_in__max',\n",
              "       'breath_id__u_in__mean', 'breath_id__u_in__diffmax',\n",
              "       'breath_id__u_in__diffmean', 'u_in_diff1', 'u_out_diff1',\n",
              "       'u_in_diff2', 'u_out_diff2', 'u_in_diff3', 'u_out_diff3',\n",
              "       'u_in_diff4', 'u_out_diff4', 'u_in_cummean', 'breath_id__u_in_lag',\n",
              "       'breath_id__u_in_lag2', 'time_step_diff', 'ewm_u_in_mean',\n",
              "       '15_in_sum', '15_in_min', '15_in_max', '15_in_mean',\n",
              "       'u_in_lagback_diff1', 'u_out_lagback_diff1', 'u_in_lagback_diff2',\n",
              "       'u_out_lagback_diff2'], dtype='<U25')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "COL_ORDER = list(train.columns[:3]) + list(train.columns[-15:]) + list(train.columns[3:-15])\n",
        "train = train[COL_ORDER]\n",
        "test = test[COL_ORDER]\n",
        "\n",
        "print('Train columns:')\n",
        "np.array( COL_ORDER )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZS9dAn6_aJc"
      },
      "source": [
        "Normalize Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbFQpdee_aJd"
      },
      "outputs": [],
      "source": [
        "RS = RobustScaler()\n",
        "train = RS.fit_transform(train.astype('float32'))\n",
        "test = RS.transform(test.astype('float32'))\n",
        "\n",
        "train = train.reshape(-1, 80, train.shape[-1])\n",
        "test = test.reshape(-1, 80, train.shape[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyVyBz6E_aJe"
      },
      "source": [
        "Mask Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICj6ohbB_aJf"
      },
      "outputs": [],
      "source": [
        "U_OUT_IDX = 2\n",
        "y_weight = np.ones_like( targets )\n",
        "u_out_values = train[:,:,U_OUT_IDX]\n",
        "y_weight[ u_out_values==0 ] = 0 # because robust scaler changes 1 to 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q8XYecL_aJg",
        "outputId": "4988128e-154f-4242-bc3a-c93c6d28f380"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((75450, 80, 64), (75450, 80, 3), (75450, 80, 3))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.shape, targets.shape, y_weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xMOt7T-_aJh"
      },
      "source": [
        "Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf_spVsC_aJh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM,GRU,SimpleRNN, RNN, Input, Bidirectional,LayerNormalization,BatchNormalization\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from sklearn.metrics import mean_squared_error "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrP1wTPD_aJi"
      },
      "outputs": [],
      "source": [
        "# n=5\n",
        "# cross_method = KFold(n_splits=n, shuffle=True)\n",
        "\n",
        "# opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# def model_fit(models, epochs = 50,batch_size = 64):\n",
        "#     t=0 #KFlod times\n",
        "#     mse = np.zeros(len(models))\n",
        "#     mae = np.zeros(len(models))\n",
        "#     # for train_index, test_index in cross_method.split(train, targets):\n",
        "#     for train_index, test_index in cross_method(train, targets,test_size=0.2):\n",
        "#         X_train, X_valid = train[train_index], train[test_index]\n",
        "#         y_train, y_valid = targets[train_index], targets[test_index]\n",
        "#         for id , model in enumerate(models):\n",
        "#             model.fit(X_train, y_train , epochs = epochs, batch_size = batch_size ,validation_data = (X_valid, y_valid))\n",
        "#             y_pred = model.predict(X_valid)\n",
        "#             for i in range(len(y_pred)):\n",
        "#                 mse[id] += mean_squared_error(y_valid[i], y_pred[i]) / n\n",
        "#                 mae[id] += mean_absolute_error(y_valid[i], y_pred[i]) / n\n",
        "\n",
        "#         t+=1\n",
        "#         print(t,\"/10\")\n",
        "#     mse = mse/len(y_pred)\n",
        "#     mae = mae/len(y_pred)\n",
        "    \n",
        "#     return(mse, mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r9p2JYU_aJj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "# cross_method = train_test_split\\\n",
        "model_dir = 'lab2-logs/model/'\n",
        "# os.makedirs(model_dir)  \n",
        "log_dir = os.path.join('lab2-logs', 'model')\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "checkpoint_filepath = \"Best_model.hdf5\"\n",
        "# sv = keras.callbacks.ModelCheckpoint(\n",
        "#         checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "#         save_weights_only=True,\n",
        "#         mode='auto', save_freq='epoch',\n",
        "#         options=None)\n",
        "tb = keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)\n",
        "rlrop = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",factor=0.1,patience=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNgaJyI3_aJk",
        "outputId": "3a1aa559-5d70-4aa7-8559-9922ae1d140e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------- > Fold 1 < ---------------\n",
            "--------------- > Fold 2 < ---------------\n",
            "--------------- > Fold 3 < ---------------\n",
            "--------------- > Fold 4 < ---------------\n",
            "--------------- > Fold 5 < ---------------\n"
          ]
        }
      ],
      "source": [
        "NUM_FOLDS = 5\n",
        "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=2021)\n",
        "test_preds = []\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
        "  print('-'*15, '>', f'Fold {fold+1}', '<', '-'*15)\n",
        "  X_train, X_valid = train[train_idx], train[test_idx]\n",
        "  y_train, y_valid = targets[train_idx], targets[test_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9OgdB42_aJl"
      },
      "outputs": [],
      "source": [
        "\n",
        "def model_fit(models, epoch = 50,batch_size = 64,path = checkpoint_filepath):\n",
        "    \n",
        "    \n",
        "    t=0 #KFlod times\n",
        "    predict_result = []\n",
        "    mse = np.zeros(len(models))\n",
        "    mae = np.zeros(len(models))\n",
        "    # for train_index, test_index in cross_method.split(train, targets):\n",
        "    # for train_index, test_index in cross_method(train, targets,test_size=0.2):\n",
        "    # X_train, X_valid,y_train, y_valid = train_test_split(train,targets,test_size=0.2)\n",
        "    for id , model in enumerate(models):\n",
        "        sv = keras.callbacks.ModelCheckpoint(\n",
        "        path, monitor='val_loss', verbose=1, save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        mode='auto', save_freq='epoch',\n",
        "        options=None)\n",
        "    \n",
        "        model.fit(X_train, y_train , epochs = epoch, batch_size = batch_size ,validation_data = (X_valid, y_valid ,y_weight[test_idx,:,:1]),callbacks=[sv, tb, rlrop],sample_weight=y_weight[train_idx,:,:1])\n",
        "        y_pred = model.predict(X_valid)\n",
        "        for i in range(len(y_pred)):\n",
        "            mse[id] += mean_squared_error(y_valid[i], y_pred[i]) \n",
        "            mae[id] += mean_absolute_error(y_valid[i], y_pred[i])\n",
        "        predict_result.append(model.predict(test))\n",
        "        # t+=1\n",
        "        # print(t,\"/10\")\n",
        "    mse = mse/len(y_pred)\n",
        "    mae = mae/len(y_pred)\n",
        "    \n",
        "\n",
        "    return(mse, mae,predict_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJJAUS7d_aJm",
        "outputId": "cc2a37a5-7bd8-415a-82c4-3cdae72ffc4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, None, 128)         98816     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 64)          49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 3)           195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,419\n",
            "Trainable params: 148,419\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_LSTM(out_dim=3):    ##build and compile LSTM model\n",
        "    \n",
        "    model=Sequential()\n",
        "    model.add(LSTM(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(LSTM(64,input_shape= [None,64], return_sequences =  True))\n",
        "    model.add(Dense(out_dim))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt, weighted_metrics = keras.losses.MeanAbsoluteError())\n",
        "    return model\n",
        "    \n",
        "model_LSTM = create_LSTM()\n",
        "model_LSTM.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqjWaUqB_aJn",
        "outputId": "297c5ae2-ee39-4cc9-be3b-7ce2a9b65b89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, None, 128)         74496     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, None, 64)          37248     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 3)           195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 111,939\n",
            "Trainable params: 111,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_GRU(out_dim=3):    ##build and compile GRU model\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(GRU(64,input_shape= [None,64],return_sequences = True))\n",
        "    model.add(Dense(out_dim))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt, weighted_metrics = keras.losses.MeanAbsoluteError())\n",
        "    return model\n",
        "    \n",
        "model_GRU = create_GRU()\n",
        "model_GRU.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOAJpoyz_aJo",
        "outputId": "3c7e3411-6fc6-4c07-8342-d2d8e3c19753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "944/944 [==============================] - ETA: 0s - loss: 0.1363 - mean_absolute_error: 3.4697\n",
            "Epoch 1: val_loss improved from inf to 0.13995, saving model to model_basic.hdf5\n",
            "944/944 [==============================] - 245s 259ms/step - loss: 0.1363 - mean_absolute_error: 3.4697 - val_loss: 0.1399 - val_mean_absolute_error: 3.4486 - lr: 0.0010\n",
            "472/472 [==============================] - 26s 54ms/step\n",
            "1572/1572 [==============================] - 76s 48ms/step\n"
          ]
        }
      ],
      "source": [
        "models = [model_LSTM,model_GRU]\n",
        "result = model_fit(models,epoch=1,path= 'model_basic.hdf5')\n",
        "print(\"LSTM :\")\n",
        "print(f\"    MSE = {result[0][0]:.5f}, MAE = {result[0][1]:.5f}\")  \n",
        "print(\"GRU :\")\n",
        "print(f\"    MSE = {result[1][0]:.5f}, MAE = {result[1][1]:.5f}\") \n",
        "model_predict = pd.DataFrame(np.array(result[2]).reshape([-1,3]),columns = ['pressure','pressure_diff','pressure_cumsum'])\n",
        "model_predict.index +=1\n",
        "model_predict[:4024000]['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/basic_results-lstm.csv',index_label='id')\n",
        "model_predict_gru = model_predict[4024000:]['pressure'].reset_index()\n",
        "model_predict_gru.index += 1\n",
        "model_predict_gru['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/basic_results-gru.csv',index_label = 'id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O5gUiPN_aJp",
        "outputId": "1b2aaeea-8dcc-4d98-ec89-7242edcd3cd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pressure</th>\n",
              "      <th>pressure_diff</th>\n",
              "      <th>pressure_cumsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.686353</td>\n",
              "      <td>-0.003121</td>\n",
              "      <td>0.036551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.642247</td>\n",
              "      <td>-0.375608</td>\n",
              "      <td>0.081033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.743396</td>\n",
              "      <td>0.901900</td>\n",
              "      <td>0.094866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.828964</td>\n",
              "      <td>1.017391</td>\n",
              "      <td>0.115886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.112551</td>\n",
              "      <td>1.253094</td>\n",
              "      <td>0.171885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047995</th>\n",
              "      <td>35.730602</td>\n",
              "      <td>0.596696</td>\n",
              "      <td>4.048653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047996</th>\n",
              "      <td>36.077049</td>\n",
              "      <td>0.464973</td>\n",
              "      <td>4.066438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047997</th>\n",
              "      <td>36.424080</td>\n",
              "      <td>0.510211</td>\n",
              "      <td>4.065267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047998</th>\n",
              "      <td>37.263638</td>\n",
              "      <td>0.377469</td>\n",
              "      <td>4.007729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8047999</th>\n",
              "      <td>38.295811</td>\n",
              "      <td>0.773748</td>\n",
              "      <td>4.227304</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8048000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          pressure  pressure_diff  pressure_cumsum\n",
              "0         5.686353      -0.003121         0.036551\n",
              "1         5.642247      -0.375608         0.081033\n",
              "2         6.743396       0.901900         0.094866\n",
              "3         7.828964       1.017391         0.115886\n",
              "4         9.112551       1.253094         0.171885\n",
              "...            ...            ...              ...\n",
              "8047995  35.730602       0.596696         4.048653\n",
              "8047996  36.077049       0.464973         4.066438\n",
              "8047997  36.424080       0.510211         4.065267\n",
              "8047998  37.263638       0.377469         4.007729\n",
              "8047999  38.295811       0.773748         4.227304\n",
              "\n",
              "[8048000 rows x 3 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model_predict = pd.DataFrame(np.array(result[2]).reshape([-1,3]),columns = ['pressure','pressure_diff','pressure_cumsum'])\n",
        "# model_predict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM81AMbm_aJq"
      },
      "source": [
        "Add BatchNormalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RO4VUAq_aJr"
      },
      "source": [
        "Build BN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jUCYixb_aJr"
      },
      "outputs": [],
      "source": [
        "def create_LSTM_BN(out_dim=3):    ##build and compile LSTM model\n",
        "    \n",
        "    model=Sequential()\n",
        "    model.add(LSTM(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LSTM(64,input_shape= [None,64], return_sequences =  True))\n",
        "    model.add(Dense(out_dim,activation=\"linear\"))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt)\n",
        "    return model\n",
        "    \n",
        "model_LSTM_BN = create_LSTM_BN()\n",
        "model_LSTM_BN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6_8320N_aJs"
      },
      "outputs": [],
      "source": [
        "def create_GRU_BN(out_dim=3):    ##build and compile GRU model\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GRU(64,input_shape= [None,64],return_sequences = True))\n",
        "    model.add(Dense(out_dim))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt)\n",
        "    return model\n",
        "    \n",
        "model_GRU_BN = create_GRU_BN()\n",
        "model_GRU_BN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFDMrcnK_aJs"
      },
      "outputs": [],
      "source": [
        "models = [model_LSTM_BN,model_GRU_BN]\n",
        "result = model_fit(models,path= 'model_BN.hdf5')\n",
        "print(\"LSTM_BN :\")\n",
        "print(f\"    MSE = {result[0][0]:.5f}, MAE = {result[0][1]:.5f}\")  \n",
        "print(\"GRU_BN :\")\n",
        "print(f\"    MSE = {result[1][0]:.5f}, MAE = {result[1][1]:.5f}\") \n",
        "model_predict = pd.DataFrame(np.array(result[2]).reshape([-1,3]),columns = ['pressure','pressure_diff','pressure_cumsum'])\n",
        "model_predict.index +=1\n",
        "model_predict[:4024000]['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/BN_results-lstm.csv',index_label='id')\n",
        "model_predict_gru = model_predict[4024000:]['pressure'].reset_index()\n",
        "model_predict_gru.index += 1\n",
        "model_predict_gru['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/BN_results-gru.csv',index_label='id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6b-LXd9_aJt"
      },
      "outputs": [],
      "source": [
        "def create_LSTM_LN(out_dim=3):    ##build and compile LSTM model\n",
        "    \n",
        "    model=Sequential()\n",
        "    model.add(LSTM(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(LSTM(64,input_shape= [None,64], return_sequences =  True))\n",
        "    model.add(Dense(out_dim,activation=\"linear\"))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt)\n",
        "    return model\n",
        "    \n",
        "model_LSTM_LN = create_LSTM_LN()\n",
        "model_LSTM_LN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbsOr6ue_aJt"
      },
      "outputs": [],
      "source": [
        "def create_GRU_LN(out_dim=3):    ##build and compile GRU model\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(GRU(128,input_shape= [None,64], return_sequences = True))\n",
        "    model.add(LayerNormalization())\n",
        "    model.add(GRU(64,input_shape= [None,64],return_sequences = True))\n",
        "    model.add(Dense(out_dim))\n",
        "    \n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt)\n",
        "    return model\n",
        "    \n",
        "model_GRU_LN = create_GRU_LN()\n",
        "model_GRU_LN.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVBpX-ZW_aJu"
      },
      "outputs": [],
      "source": [
        "LN_models = [model_LSTM_LN,model_GRU_LN]\n",
        "result = model_fit(LN_models,path= 'model_LN.hdf5')\n",
        "print(\"LSTM_LN :\")\n",
        "print(f\"    MSE = {result[0][0]:.5f}, MAE = {result[0][1]:.5f}\")  \n",
        "print(\"GRU_LN :\")\n",
        "print(f\"    MSE = {result[1][0]:.5f}, MAE = {result[1][1]:.5f}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7We_Vi3_aJu"
      },
      "outputs": [],
      "source": [
        "model_predict = pd.DataFrame(np.array(result[2]).reshape([-1,3]),columns = ['pressure','pressure_diff','pressure_cumsum'])\n",
        "model_predict.index +=1\n",
        "model_predict[:4024000]['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/LN_results-lstm.csv',index_label=\"id\")\n",
        "model_predict_gru = model_predict[4024000:]['pressure'].reset_index()\n",
        "model_predict_gru.index += 1\n",
        "model_predict_gru['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/LN_results-gru.csv',index_label=\"id\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8kpc0sL_aJu"
      },
      "source": [
        "Build BiLSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFBbd7Tz_aJv"
      },
      "outputs": [],
      "source": [
        "def create_biLSTM(out_dim=3):    ##build and compile LSTM model\n",
        "    \n",
        "    input = Input(shape=[None,64])\n",
        "\n",
        "    layer_BiLSTM1 = Bidirectional(LSTM(128,input_shape= [None,64], return_sequences = True))(input)\n",
        "    layer_BiLSTM2 = Bidirectional(LSTM(128,input_shape= [None,64], return_sequences = True))(layer_BiLSTM1)\n",
        "    layer_output = Dense(out_dim,activation=\"linear\")(layer_BiLSTM2)\n",
        "    \n",
        "    model = keras.models.Model(inputs = input,outputs = layer_output)\n",
        "\n",
        "    model.compile(loss='mean_absolute_error',optimizer=opt)\n",
        "    return model\n",
        "    \n",
        "model_biLSTM = create_biLSTM()\n",
        "model_biLSTM.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L_8XZj9_aJv"
      },
      "outputs": [],
      "source": [
        "model = [model_biLSTM]\n",
        "result = model_fit(model,path='model_biLSTM.hdf5')\n",
        "print(\"LSTM_Bi :\")\n",
        "print(f\"    MSE = {float(result[0]):.5f}, MAE = {float(result[1]):.5f}\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pnb_QQ2f_aJw"
      },
      "outputs": [],
      "source": [
        "model_predict = pd.DataFrame(np.array(result[2]).reshape([-1,3]),columns = ['pressure','pressure_diff','pressure_cumsum'])\n",
        "model_predict.index +=1\n",
        "model_predict['pressure'].to_csv('/content/drive/MyDrive/數據科學方法/Computer Project/ventilator-pressure-prediction/BiLSTM_results.csv',index_label='id')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f8960d39c225454f240bf28119db3bd1c2af9d1e10bbe46bdd32d696d33742dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
